#include <stdio.h>
#include <mpi.h>

int main(int argc, char *argv[]) {
    int rank, size;
    MPI_Comm comm_cart; // Новый коммуникатор для декартовой топологии
    int dims[2];        // Размеры решетки (2 строки x N столбцов)
    int periods[2];     // Периодичность (замкнутость границ)
    int reorder = 0;    // Разрешение на перенумерацию рангов (0 - запрещено)
    int my_coords[2];   // Координаты текущего процесса в решетке [y, x]
    int rank_source, rank_dest; // Ранги соседей для приема и отправки
    
    double A_send; // Число, которое мы отправляем
    double A_recv; // Число, которое мы принимаем

    /* * MPI_Init
     * Инициализирует среду MPI. Должна быть вызвана первой.
     * Аргументы:
     * &argc, &argv - указатели на аргументы командной строки (передаются из main).
     */
    MPI_Init(&argc, &argv);

    /*
     * MPI_Comm_rank
     * Определяет ранг (идентификатор) текущего процесса.
     * Аргументы:
     * MPI_COMM_WORLD - коммуникатор по умолчанию (все запущенные процессы).
     * &rank - куда записать номер текущего процесса (0, 1, 2...).
     */
    MPI_Comm_rank(MPI_COMM_WORLD, &rank);

    /*
     * MPI_Comm_size
     * Определяет общее количество процессов.
     * Аргументы:
     * MPI_COMM_WORLD - коммуникатор.
     * &size - куда записать общее число процессов.
     */
    MPI_Comm_size(MPI_COMM_WORLD, &size);

    // 1. Проверка условия: K = 2N, N > 1 (т.е. size четное и > 2)
    if (size % 2 != 0 || size <= 2) {
        if (rank == 0) {
            fprintf(stderr, "Ошибка: Число процессов K=%d должно быть четным и > 2.\n", size);
        }
        // Завершаем работу, если условия не соблюдены
        MPI_Finalize();
        return 1;
    }

    int N = size / 2;
    
    // Инициализируем данные (каждый процесс отправляет свой номер как число)
    A_send = (double)rank;

    // 2. Настройка параметров топологии 2xN
    dims[0] = 2; // Количество строк
    dims[1] = N; // Количество столбцов

    // periods[0] = 0 -> Измерение 0 (строки/вертикаль) НЕ замкнуто
    // periods[1] = 1 -> Измерение 1 (столбцы/горизонталь) ЗАМКНУТО (циклическое)
    periods[0] = 0;
    periods[1] = 1; 

    /*
     * MPI_Cart_create
     * Создает новый коммуникатор с декартовой (решетчатой) топологией.
     * Аргументы:
     * MPI_COMM_WORLD - старый коммуникатор, из которого берем процессы.
     * 2 - размерность решетки (двумерная).
     * dims - массив размеров решетки [2, N].
     * periods - массив логических флагов замкнутости границ (цикличность).
     * reorder - (0 или 1). 0 означает, что ранги в новом коммуникаторе останутся такими же, как в старом.
     * &comm_cart - указатель, куда записать дескриптор нового коммуникатора.
     */
    MPI_Cart_create(MPI_COMM_WORLD, 2, dims, periods, reorder, &comm_cart);

    /*
     * MPI_Cart_coords
     * Получает координаты процесса в решетке по его рангу.
     * Аргументы:
     * comm_cart - коммуникатор с топологией.
     * rank - ранг процесса, чьи координаты ищем (свой собственный).
     * 2 - размерность координат (у нас 2D).
     * my_coords - массив, куда запишется результат (например, [0, 1]).
     */
    MPI_Cart_coords(comm_cart, rank, 2, my_coords);

    /*
     * MPI_Cart_shift
     * Вычисляет ранги соседей для сдвига данных вдоль одного измерения.
     * Аргументы:
     * comm_cart - коммуникатор.
     * 1 - направление сдвига (direction). 0 - вдоль вертикали, 1 - вдоль горизонтали (строки).
     * 1 - величина сдвига (displacement). +1 означает сдвиг "вправо" (к большему индексу).
     * &rank_source - сюда запишется ранг соседа, от которого придут данные (левый сосед).
     * &rank_dest - сюда запишется ранг соседа, КОТОРОМУ мы шлем данные (правый сосед).
     * Примечание: Благодаря periods[1]=1, на границах будет возвращен ранг с другого конца строки (цикл).
     */
    MPI_Cart_shift(comm_cart, 1, 1, &rank_source, &rank_dest);

    /*
     * MPI_Sendrecv
     * Одновременно отправляет и принимает сообщение. Это предотвращает взаимную блокировку (deadlock).
     * Аргументы:
     * &A_send - буфер отправки (что шлем).
     * 1 - количество элементов отправки.
     * MPI_DOUBLE - тип отправляемых данных.
     * rank_dest - ранг получателя (кому шлем).
     * 0 - тег сообщения (идентификатор типа сообщения).
     * * &A_recv - буфер приема (куда кладем принятое).
     * 1 - количество элементов приема.
     * MPI_DOUBLE - тип принимаемых данных.
     * rank_source - ранг отправителя (от кого ждем).
     * 0 - тег сообщения (должен совпадать с тегом отправки).
     * * comm_cart - коммуникатор, в рамках которого идет обмен.
     * MPI_STATUS_IGNORE - нам не нужны детали статуса завершения (ошибки, реальное кол-во байт).
     */
    MPI_Sendrecv(
        &A_send, 1, MPI_DOUBLE, rank_dest, 0,
        &A_recv, 1, MPI_DOUBLE, rank_source, 0,
        comm_cart, MPI_STATUS_IGNORE
    );

    /*
     * MPI_Barrier
     * Блокирует вызвавший процесс, пока ВСЕ остальные процессы в коммуникаторе не дойдут до этой точки.
     * Используется здесь для красивого последовательного вывода на экран (чтобы строки не перемешались).
     * Аргумент: comm_cart - коммуникатор.
     */
    MPI_Barrier(comm_cart); 
    
    int i;
    for (i = 0; i < size; i++) {
        if (rank == i) {
            printf("Ранг %d (Коорд: [%d, %d]): Исходное A = %.1f, Полученное A = %.1f (от Ранга %d)\n",
                   rank, my_coords[0], my_coords[1], A_send, A_recv, rank_source);
        }
        // Барьер внутри цикла гарантирует, что процесс i+1 не начнет печать, пока процесс i не закончит.
        MPI_Barrier(comm_cart); 
    }

    /*
     * MPI_Comm_free
     * Освобождает память, выделенную под коммуникатор.
     * Аргумент: &comm_cart - указатель на коммуникатор для удаления.
     */
    MPI_Comm_free(&comm_cart);
    
    /*
     * MPI_Finalize
     * Завершает работу MPI. Освобождает все ресурсы MPI.
     * После этой функции вызывать другие функции MPI запрещено.
     */
    MPI_Finalize();
    
    return 0;
}
