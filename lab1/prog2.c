#include <stdio.h> 
#include <stdlib.h> 
#include "mpi.h"    

// Главная функция программы
// argc - количество аргументов командной строки
// argv - массив строк (сами аргументы)
int main(int argc, char *argv[]) {

    
    int ProcRank, ProcNum, RecvRank; // Объявление целочисленных переменных
                                     // ProcRank: Ранг (ID) текущего процесса
                                     // ProcNum: Общее число процессов
                                     // RecvRank: Буфер для ранга, полученного от другого процесса

    int n = 0; // Размер задачи, инициализирован 0
    
    // Объявление структуры MPI_Status для получения информации о сообщении
    MPI_Status Status; 
    
    // Переменные для хранения времени начала и конца
    double start_time, end_time; 

    
    // Инициализация среды MPI, ОБЯЗАТЕЛЬНАЯ первая MPI-функция
    MPI_Init(&argc, &argv); 
    // Получаем общее число запущенных процессов (записываем в ProcNum)
    MPI_Comm_size(MPI_COMM_WORLD, &ProcNum); 
    // Получаем ранг (ID) этого процесса (записываем в ProcRank)
    MPI_Comm_rank(MPI_COMM_WORLD, &ProcRank); 

    
    // Только "главный" процесс (с рангом 0) будет считывать аргументы.
    if (ProcRank == 0) { 
        // Проверяем, был ли передан аргумент (argc < 2 означает, что передано только имя программы)
        if (argc < 2) { 
            // Если 'n' не указан, выводим предупреждение на stderr
            fprintf(stderr, "Предупреждение: Размер задачи 'n' не указан. Используется n=0.\n");
            n = 0; // Используем n=0 по умолчанию
        } else { // Если аргумент есть
            // Преобразуем строковый аргумент (argv[1]) в целое число
            n = atoi(argv[1]); 
            if (n <= 0) { // Проверяем, что 'n' - положительное
                // Если 'n' некорректно, выводим ошибку на stderr
                fprintf(stderr, "Ошибка: Размер задачи 'n' должен быть положительным числом.\n");
                n = -1; // Устанавливаем 'n' в -1 как флаг ошибки
            }
        }
    }

    /* * КОЛЛЕКТИВНАЯ ОПЕРАЦИЯ: "Широковещательная рассылка" (Broadcast)
     * Процесс 0 рассылает значение из своей переменной 'n'
     * всем остальным процессам. Все остальные - принимают и записывают в свою 'n'.
     */
    MPI_Bcast(&n, 1, MPI_INT, 0, MPI_COMM_WORLD); 
    
    // Теперь ВСЕ процессы (не только 0) проверяют, не был ли установлен флаг ошибки
    if (n == -1) {
        MPI_Finalize(); // Если да, все синхронно завершают MPI
        return 1;       // и выходят из программы с кодом ошибки
    }

    
    /* * КОЛЛЕКТИВНАЯ ОПЕРАЦИЯ: "Барьер"
     * Все процессы "зависают" на этой строке, пока КАЖДЫЙ из них до нее не дойдет.
     * Это гарантирует, что все начнут замер времени одновременно.
     */
    MPI_Barrier(MPI_COMM_WORLD); 
    
    // Каждый процесс засекает свое локальное время (в секундах)
    start_time = MPI_Wtime(); 

    
    // Логика делится: что делает процесс 0 и что делают все остальные.
    if (ProcRank == 0) { // Если я "мастер" (ранг 0)
        // Процесс 0 сначала печатает "Hello" от себя
        printf("Hello from process %3d\n", ProcRank); 

        // Затем он в цикле принимает сообщения от ВСЕХ остальных (от 1 до ProcNum-1)
        for (int i = 1; i < ProcNum; i++) {
            /* * ОПЕРАЦИЯ "ПРИЕМ": Процесс 0 блокируется (ждет)
             * &RecvRank: буфер, куда положить принятые данные
             * 1, MPI_INT: ожидаемое кол-во и тип данных
             * i: ВАЖНО! Ждать сообщение конкретно от процесса 'i'.
             * Сначала от 1, потом от 2, и т.д. (СТРОГО ПО ПОРЯДКУ)
             * 0: ожидаемый тег сообщения
             * &Status: структура, куда запишется информация (от кого пришло)
             */
            MPI_Recv(&RecvRank, 1, MPI_INT, i, 0, MPI_COMM_WORLD, &Status);
            
            // Печатаем ранг, который мы ФАКТИЧЕСКИ получили
            printf("Hello from process %3d\n", RecvRank); 
        }
    } else { // Если я "рабочий" (ранг 1, 2, 3...)
        /*
         * ОПЕРАЦИЯ "ОТПРАВКА":
         * &ProcRank: адрес данных для отправки (отправляем свой ранг)
         * 1, MPI_INT: кол-во и тип данных
         * 0: ранг получателя (отправляем процессу 0)
         * 0: тег сообщения
         */
        MPI_Send(&ProcRank, 1, MPI_INT, 0, 0, MPI_COMM_WORLD);
    } // --- Конец основной логики ---

    // --- 5. ОКОНЧАНИЕ ЗАМЕРА ВРЕМЕНИ ---
    
    // Снова ставим барьер, чтобы процесс 0 не закончил замер времени
    // раньше, чем все остальные процессы отправят ему сообщения.
    MPI_Barrier(MPI_COMM_WORLD); 
    
    // Каждый процесс фиксирует свое локальное время окончания
    end_time = MPI_Wtime(); 

    
    // Только процесс 0 выводит итоговое время
    if (ProcRank == 0) { 
        // Считаем разницу (на машине процесса 0) и выводим
        printf("\nTotal execution time for n=%d: %f seconds\n", n, end_time - start_time);
    }

    
    // Корректно завершаем работу MPI. Обязательная функция в конце.
    MPI_Finalize(); 
    
    // Все процессы успешно завершают программу
    return 0; 
}
